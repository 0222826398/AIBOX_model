{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"Destination Port\", \"Flow Duration\", \"Flow Bytes/s\", \"Flow Packets/s\", \"Fwd Packets/s\", \"Bwd Packets/s\", \"Total Fwd Packets\", \"Total Backward Packets\", \"Total Length of Fwd Packets\", \n",
    "\"Total Length of Bwd Packets\", \"Fwd Packet Length Max\", \"Fwd Packet Length Min\", \"Fwd Packet Length Mean\", \"Fwd Packet Length Std\", \"Bwd Packet Length Max\", \"Bwd Packet Length Min\", \n",
    "\"Bwd Packet Length Mean\", \"Bwd Packet Length Std\", \"Max Packet Length\", \"Min Packet Length\", \"Packet Length Mean\", \"Packet Length Std\", \"Packet Length Variance\", \"Fwd Header Length\", \n",
    "\"Bwd Header Length\", \"min_seg_size_forward\", \"act_data_pkt_fwd\", \"Flow IAT Mean\", \"Flow IAT Max\", \"Flow IAT Min\", \"Flow IAT Std\", \"Fwd IAT Total\", \"Fwd IAT Max\", \"Fwd IAT Min\", \"Fwd IAT Mean\", \n",
    "\"Fwd IAT Std\", \"Bwd IAT Total\", \"Bwd IAT Max\", \"Bwd IAT Min\", \"Bwd IAT Mean\", \"Bwd IAT Std\", \"Fwd PSH Flags\", \"Bwd PSH Flags\", \"Fwd URG Flags\", \"Bwd URG Flags\", \"FIN Flag Count\", \"SYN Flag Count\", \n",
    "\"RST Flag Count\", \"PSH Flag Count\", \"ACK Flag Count\", \"URG Flag Count\", \"ECE Flag Count\", \"Down/Up Ratio\", \"Average Packet Size\", \"Init_Win_bytes_forward\", \"Init_Win_bytes_backward\", \"Active Max\", \n",
    "\"Active Min\", \"Active Mean\", \"Active Std\", \"Idle Max\", \"Idle Min\", \"Idle Mean\", \"Idle Std\", \"Fwd Avg Bytes/Bulk\", \"Fwd Avg Packets/Bulk\", \"Bwd Avg Bytes/Bulk\", \"Bwd Avg Packets/Bulk\", \"Fwd Avg Bulk Rate\", \n",
    "\"Bwd Avg Bulk Rate\", \"Avg Fwd Segment Size\", \"Avg Bwd Segment Size\", \"CWE Flag Count\", \"Subflow Fwd Packets\", \"Subflow Bwd Packets\", \"Subflow Fwd Bytes\", \"Subflow Bwd Bytes\", \"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原始資料集處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# week.csv為原始資料及concat檔案\n",
    "df = pd.read_csv(\"MachineLearningCSV/MachineLearningCVE/week.csv\")\n",
    "df.to_csv(\"MachineLearningCSV/MachineLearningCVE/week.csv\", index = False)\n",
    "df.to_csv(\"MachineLearningCSV/MachineLearningCVE/week_2.csv\", columns = columns, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新資料集處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearningCSV/test\\testflows.csv\n",
      "MachineLearningCSV/test\\testflows10.csv\n",
      "MachineLearningCSV/test\\testflows11.csv\n",
      "MachineLearningCSV/test\\testflows12.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "csv_files = []\n",
    "for dirname, _, filenames in os.walk('MachineLearningCSV/NewDataSet'):\n",
    "    for filename in filenames:\n",
    "        csv_file = os.path.join(dirname, filename)\n",
    "        print(os.path.join(dirname, filename))\n",
    "        csv_files.append(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新資料集位置調整\n",
    "df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "# df = pd.read_csv(\"MachineLearningCSV/NewDateSet/DrDoS_DNS_data_1_per.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取樣\n",
    "df = df.sample(n = 1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"MachineLearningCSV/NewDateSet/NewDataSet_1.5m.csv\", columns = columns, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MachineLearningCSV/NewDateSet/NewDataSet_500k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3499bcc59dd07de3752bcaf4b431b7cc0c8d7df018f3c7c8f72730d6f0400322"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
